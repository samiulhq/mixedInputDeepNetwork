{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sweetpotato Shape Classification \n",
    "This is an example on how to train mixed input deep network in kearas. The network is trained on sweetpotato images labeled as 'Cull' and 'Good'. There are three types of input 1) Near Infrared Images of Sweetpotato, 2) RGB Images of Sweetpotato, 3) Shape Features extracted from computer vision algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Images from Directory as Training and Validation Set\n",
    "\n",
    "We use Keras flow_from_directory API to not overload the computer memory. ImageDataGenerator class has been used to create train and validation set. However, since we are creating a mixed input deep network, we have to design a custom data generator to genearte mixed data (Image and Numeric features) on the fly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define image height, width, training batch size, number of classes, and class names here\n",
    "We want to identify cull vs good sweetpotato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "py = 128*2  # height\n",
    "px = 96*2  # widht\n",
    "batch_size=32\n",
    "\n",
    "\n",
    "class_names=['Cull','Good']\n",
    "class_num=len(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a 80% : 20% training and validation split resulting in \n",
    "\n",
    "### 1080 Training images\n",
    "### 269 Validation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1. / 255, dtype=np.float32, horizontal_flip=True, vertical_flip=True, validation_split=0.2,\n",
    "        rotation_range=15)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255, dtype=np.float32)\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'L:/Sweetpotato Classification/Data/Training_Binary_Kenn',  # this is the target directory\n",
    "        target_size=(py, px,3),  # all images will be resized to height*width\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical', subset='training',\n",
    "        classes=class_names)  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "        'L:/Sweetpotato Classification/Data/Training_Binary_Kenn',\n",
    "        target_size=(py, px,3),\n",
    "        batch_size=batch_size,        \n",
    "        class_mode='categorical', subset='validation', classes=class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained VGG 16 Model\n",
    "\n",
    "We load the VGG16 model with pretrained weight, excluding the top layer and freez the Convolutional layers during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "model_vgg16_NIR = VGG16(weights='imagenet', include_top=False,input_shape=(py,px,3))\n",
    "#model_vgg16_NIR.summary()\n",
    "\n",
    "#keras_input = Input(shape=(py,px,3,), name = 'image_input')\n",
    "    \n",
    "#Use the generated model \n",
    "#output_vgg16_NIR = model_vgg16_NIR(keras_input)\n",
    "for layer in model_vgg16_NIR.layers[:-4]:\n",
    "    layer.trainable = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg16_RGB = VGG16(weights='imagenet', include_top=False,input_shape=(py,px,3))\n",
    "#model_vgg16_conv.summary()\n",
    "\n",
    "#keras_input = Input(shape=(py,px,3,), name = 'image_input')\n",
    "for i, layer in enumerate(model_vgg16_RGB.layers):\n",
    "    layer.name = 'layer_' + str(i)    \n",
    "#Use the generated model \n",
    "#output_vgg16_conv = model_vgg16_conv(keras_input)\n",
    "for layer in model_vgg16_RGB.layers[:-4]:\n",
    "    layer.trainable = False "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Layer Percptron Model\n",
    "\n",
    "We define our nerual network model that will use the engineered features for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "modelNN=Sequential()\n",
    "modelNN.add(Dense(64,input_dim=71))\n",
    "modelNN.add(Dense(64, activation=\"relu\"))\n",
    "modelNN.add(Dense(16, activation=\"relu\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging two branches \n",
    "\n",
    "We flatten the outputs from VGG16 and merge it with final dense layer of the Neural Network, add final layers and complete the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import concatenate\n",
    "flattenvgg16NIR=Flatten()(model_vgg16_NIR.output)\n",
    "flattenvgg16RGB=Flatten()(model_vgg16_RGB.output)\n",
    "combinedInput = concatenate([flattenvgg16NIR, flattenvgg16RGB, modelNN.output])\n",
    "\n",
    "x = Dense(512, activation=\"relu\")(combinedInput)\n",
    "x = Dense(128, activation=\"relu\")(x)\n",
    "x = Dense(64, activation=\"relu\")(x)\n",
    "x =Dense(2, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs=[model_vgg16_NIR.input, model_vgg16_RGB.input, modelNN.input], outputs=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define optimizer and compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "opt = Adam(lr=0.1)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the network structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model,  to_file='model_plot.png',show_shapes=True, show_layer_names=True);\n",
    "from IPython.display import Image \n",
    "Image('model_plot.png') #export as png image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom generator from mixed input\n",
    "\n",
    "\n",
    "We have image data and numeric features in csv (dataframe) format. A custom generator will generate mixed inputs with labels on the fly. This generator allow us to use the fit_predictor api for model training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cocept adapted from https://stackoverflow.com/questions/55266249/create-a-mixed-data-generator-images-csv-in-keras/55267337\n",
    "from keras.preprocessing import image as krs_image\n",
    "import random\n",
    "import threading\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def custom_generator(batch_size,images_list,feature_dataframe,validation=False):\n",
    "    idx=0\n",
    "    #images_list=train_generator.filepaths\n",
    "    # dataframe=feature_df=pd.read_csv('df_csv.csv',index_col='Title')\n",
    "  \n",
    "    data_gen_args = dict(\n",
    "    horizontal_flip=True,\n",
    "    shear_range=10,\n",
    "    channel_shift_range=50,\n",
    "    rescale=1. / 255)\n",
    "    num_classes=2\n",
    "    i = 0\n",
    "    datagen = ImageDataGenerator()\n",
    "    random.shuffle(images_list)\n",
    "    while True:\n",
    "        batch = {'images': [], 'rgbimages':[], 'csv': [], 'labels': []}\n",
    "        for b in range(batch_size):\n",
    "            if i == len(images_list):\n",
    "                i = 0\n",
    "                random.shuffle(images_list)\n",
    "            # Read image from list and convert to array\n",
    "            image_path = images_list[i]\n",
    "            image_name = os.path.basename(image_path)\n",
    "            #Create RGB Image Path\n",
    "            \n",
    "            \n",
    "            image = krs_image.load_img(image_path, target_size=(py, px))\n",
    "            if validation==False:\n",
    "                image = datagen.apply_transform(image, data_gen_args)\n",
    "            \n",
    "            image = krs_image.img_to_array(image)\n",
    "            \n",
    "            # Read data from csv using the name of current image\n",
    "\n",
    "            try:\n",
    "                csv_row = feature_dataframe.loc[image_name, :]\n",
    "            except KeyError:\n",
    "                i += 1\n",
    "                continue\n",
    "            label = csv_row['Shape']            \n",
    "            csv_features = csv_row.drop(labels='Shape')\n",
    "            \n",
    "            \n",
    "            rgb_image_name=image_name.replace('NIR','RGB')\n",
    "            rgb_image_path='L:\\\\Sweetpotato Classification\\\\Data\\\\Training_RGB_Binary\\\\'+label+'\\\\'+rgb_image_name\n",
    "           \n",
    "            rgbimage = krs_image.load_img(image_path, target_size=(py, px))\n",
    "            \n",
    "            if validation==False:\n",
    "                rgbimage = datagen.apply_transform(image, data_gen_args)\n",
    "            \n",
    "            rgbimage = krs_image.img_to_array(rgbimage)            \n",
    "            #plt.imshow(rgbimage)\n",
    "            #print(rgb_image_path)\n",
    "            batch['rgbimages'].append(rgbimage)\n",
    "            batch['images'].append(image)\n",
    "            batch['csv'].append(csv_features)\n",
    "            batch['labels'].append(label)\n",
    "           \n",
    "            i += 1\n",
    "\n",
    "        batch['images'] = np.array(batch['images'])\n",
    "        batch['csv'] = np.array(batch['csv'])\n",
    "        batch['rgbimages']=np.array(batch['rgbimages'])\n",
    "        # Convert labels to categorical values\n",
    "       \n",
    "        one_hot = [0 if x=='Cull' else 1 for x in batch['labels']]        \n",
    "        batch['labels'] = np.eye(num_classes)[one_hot]\n",
    "        #print('generator yielded a batch %d' % idx)\n",
    "        idx+=1\n",
    "        yield [batch['images'], batch['rgbimages'], batch['csv']], batch['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Read features from csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_df=pd.read_csv('df_csv.csv',index_col='Title')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training and validation image path list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_im_list=train_generator.filepaths\n",
    "val_im_list=validation_generator.filepaths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom data  generator for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "custom_train_gen=custom_generator(batch_size=batch_size,images_list=tr_im_list,feature_dataframe=feature_df)\n",
    "\n",
    "custom_validation_gen=custom_generator(batch_size=batch_size,images_list=val_im_list,\n",
    "                                       feature_dataframe=feature_df,validation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "H=model.fit_generator(custom_train_gen,steps_per_epoch=np.ceil(train_generator.samples/batch_size),\n",
    "        epochs=5,validation_data=custom_validation_gen,validation_steps=np.ceil(validation_generator.samples/batch_size));\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
